#!/usr/bin/env python3
"""
SEO ìµœì í™” ë° A4 í”„ë¦°íŠ¸ ìµœì í™”ëœ ì´ë¯¸ì§€ ìƒì„±ê¸°
ë‹¤êµ­ì–´ ì§€ì› (5ê°œ ì–¸ì–´) + A4 ì‚¬ì´ì¦ˆ ìµœì í™”
"""

import os
import json
from datetime import datetime
from image_crawler_generator import ImageCrawlerGenerator
from seo_metadata_generator import SEOMetadataGenerator

class EnhancedImageGenerator:
    def __init__(self):
        self.image_generator = ImageCrawlerGenerator()
        self.seo_generator = SEOMetadataGenerator()
        
    def generate_enhanced_coloring_pages(self, character_name: str, age_group: str, 
                                       difficulty: str, count: int = 10) -> str:
        """SEO ìµœì í™” ë° A4 í”„ë¦°íŠ¸ ìµœì í™”ëœ ìƒ‰ì¹ ë„ì•ˆ ìƒì„±"""
        
        print(f"ğŸ¨ SEO ìµœì í™” + A4 í”„ë¦°íŠ¸ ìµœì í™” ìƒ‰ì¹ ë„ì•ˆ ìƒì„±")
        print(f"ìºë¦­í„°: {character_name}, ì—°ë ¹ëŒ€: {age_group}, ë‚œì´ë„: {difficulty}")
        print("=" * 70)
        
        # 1. ê¸°ì¡´ ì´ë¯¸ì§€ ìƒì„±
        result_file = self.image_generator.generate_coloring_pages(
            character_name=character_name,
            age_group=age_group,
            difficulty=difficulty,
            count=count
        )
        
        if not result_file:
            print("âŒ ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")
            return None
        
        # 2. ìƒì„±ëœ ê²°ê³¼ ë¡œë“œ
        with open(result_file, 'r', encoding='utf-8') as f:
            result_data = json.load(f)
        
        # 3. ê° í˜ì´ì§€ì— ëŒ€í•´ SEO ë©”íƒ€ë°ì´í„° ìƒì„±
        enhanced_pages = []
        
        for i, page in enumerate(result_data.get('generated_pages', []), 1):
            print(f"\\nğŸ“ í˜ì´ì§€ {i} SEO ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
            
            # SEO ë©”íƒ€ë°ì´í„° ìƒì„±
            seo_metadata = self.seo_generator.generate_seo_metadata(
                character_name=character_name,
                age_group=age_group,
                difficulty=difficulty,
                image_url=page.get('firebase_url', ''),
                page_number=i
            )
            
            # í˜ì´ì§€ ë°ì´í„°ì— SEO ë©”íƒ€ë°ì´í„° ì¶”ê°€
            enhanced_page = {
                **page,
                'seo_metadata': seo_metadata,
                'print_optimized': True,
                'a4_size': {
                    'width': 2480,
                    'height': 3508,
                    'dpi': 300,
                    'unit': 'pixels'
                },
                'multilingual_support': list(self.seo_generator.languages.keys())
            }
            
            enhanced_pages.append(enhanced_page)
            
            # ë‹¤êµ­ì–´ ì œëª© ì¶œë ¥
            print(f"  ğŸ‡°ğŸ‡· í•œêµ­ì–´: {seo_metadata['multilingual_metadata']['ko']['seo_metadata']['title']}")
            print(f"  ğŸ‡ºğŸ‡¸ English: {seo_metadata['multilingual_metadata']['en']['seo_metadata']['title']}")
            print(f"  ğŸ‡ªğŸ‡¸ EspaÃ±ol: {seo_metadata['multilingual_metadata']['es']['seo_metadata']['title']}")
            print(f"  ğŸ‡¯ğŸ‡µ æ—¥æœ¬èª: {seo_metadata['multilingual_metadata']['ja']['seo_metadata']['title']}")
            print(f"  ğŸ‡¨ğŸ‡³ ä¸­æ–‡: {seo_metadata['multilingual_metadata']['zh']['seo_metadata']['title']}")
        
        # 4. í–¥ìƒëœ ê²°ê³¼ ë°ì´í„° êµ¬ì„±
        enhanced_result = {
            'character_name': character_name,
            'age_group': age_group,
            'difficulty': difficulty,
            'generated_at': datetime.now().isoformat(),
            'total_pages': len(enhanced_pages),
            'seo_optimized': True,
            'print_optimized': True,
            'a4_compatible': True,
            'multilingual_support': list(self.seo_generator.languages.keys()),
            'generated_pages': enhanced_pages,
            'reference_images': result_data.get('reference_images', []),
            'seo_summary': self._generate_seo_summary(enhanced_pages)
        }
        
        # 5. í–¥ìƒëœ ê²°ê³¼ ì €ì¥
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        enhanced_filename = f"enhanced_coloring_pages_{character_name}_{timestamp}.json"
        
        with open(enhanced_filename, 'w', encoding='utf-8') as f:
            json.dump(enhanced_result, f, ensure_ascii=False, indent=2)
        
        print(f"\\nâœ… í–¥ìƒëœ ìƒ‰ì¹ ë„ì•ˆ ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ íŒŒì¼: {enhanced_filename}")
        print(f"ğŸ“Š ì´ í˜ì´ì§€: {len(enhanced_pages)}ê°œ")
        print(f"ğŸŒ ì§€ì› ì–¸ì–´: {len(self.seo_generator.languages)}ê°œ")
        print(f"ğŸ–¨ï¸ A4 í”„ë¦°íŠ¸ ìµœì í™”: âœ…")
        print(f"ğŸ” SEO ìµœì í™”: âœ…")
        
        return enhanced_filename
    
    def _generate_seo_summary(self, enhanced_pages: list) -> dict:
        """SEO ìš”ì•½ ì •ë³´ ìƒì„±"""
        
        # ëª¨ë“  í‚¤ì›Œë“œ ìˆ˜ì§‘
        all_keywords = set()
        for page in enhanced_pages:
            for lang_code in self.seo_generator.languages.keys():
                keywords = page['seo_metadata']['multilingual_metadata'][lang_code]['seo_metadata']['keywords']
                all_keywords.update(keywords)
        
        # ì–¸ì–´ë³„ í‚¤ì›Œë“œ í†µê³„
        keyword_stats = {}
        for lang_code in self.seo_generator.languages.keys():
            lang_keywords = set()
            for page in enhanced_pages:
                keywords = page['seo_metadata']['multilingual_metadata'][lang_code]['seo_metadata']['keywords']
                lang_keywords.update(keywords)
            keyword_stats[lang_code] = list(lang_keywords)
        
        return {
            'total_keywords': len(all_keywords),
            'keywords_by_language': keyword_stats,
            'seo_features': [
                'Multilingual titles and descriptions',
                'Optimized keywords for each language',
                'Open Graph metadata',
                'Twitter Card metadata',
                'Structured data (JSON-LD)',
                'A4 print optimization',
                'Accessibility (Alt text)',
                'URL-friendly file naming'
            ],
            'print_features': [
                'A4 size (210x297mm)',
                '300 DPI resolution',
                '2480x3508 pixels',
                'Print-ready format',
                'Proper margins for printing'
            ]
        }
    
    def generate_sitemap_data(self, enhanced_pages: list) -> dict:
        """ì‚¬ì´íŠ¸ë§µ ë°ì´í„° ìƒì„±"""
        
        sitemap_entries = []
        
        for page in enhanced_pages:
            character_name = page['seo_metadata']['base_info']['character_name']
            page_number = page['seo_metadata']['base_info']['page_number']
            
            # ê° ì–¸ì–´ë³„ URL ìƒì„±
            for lang_code in self.seo_generator.languages.keys():
                file_naming = page['seo_metadata']['multilingual_metadata'][lang_code]['file_naming']
                
                sitemap_entry = {
                    'url': f"/coloring-pages/{file_naming['url_slug']}",
                    'lastmod': datetime.now().strftime('%Y-%m-%d'),
                    'changefreq': 'weekly',
                    'priority': 0.8,
                    'language': lang_code,
                    'title': page['seo_metadata']['multilingual_metadata'][lang_code]['seo_metadata']['title'],
                    'description': page['seo_metadata']['multilingual_metadata'][lang_code]['seo_metadata']['description']
                }
                
                sitemap_entries.append(sitemap_entry)
        
        return {
            'sitemap_entries': sitemap_entries,
            'total_urls': len(sitemap_entries),
            'languages': list(self.seo_generator.languages.keys()),
            'generated_at': datetime.now().isoformat()
        }

def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    print("ğŸš€ SEO ìµœì í™” + A4 í”„ë¦°íŠ¸ ìµœì í™” ì´ë¯¸ì§€ ìƒì„±ê¸°")
    print("=" * 70)
    
    generator = EnhancedImageGenerator()
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤
    test_cases = [
        ('í•˜ì¸„í•‘', 'child', 'easy', 3),
        ('ì•„ì´ì–¸ë¯¸ì•¼ì˜¹', 'teen', 'medium', 2),
        ('ë„ë¼ì—ëª½', 'adult', 'hard', 2)
    ]
    
    for character, age_group, difficulty, count in test_cases:
        print(f"\\nğŸ¯ {character} í…ŒìŠ¤íŠ¸ ì‹œì‘")
        print("-" * 50)
        
        result_file = generator.generate_enhanced_coloring_pages(
            character, age_group, difficulty, count
        )
        
        if result_file:
            print(f"âœ… {character} ìƒì„± ì™„ë£Œ: {result_file}")
            
            # ì‚¬ì´íŠ¸ë§µ ë°ì´í„° ìƒì„±
            with open(result_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            sitemap_data = generator.generate_sitemap_data(data['generated_pages'])
            sitemap_file = f"sitemap_{character}_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            
            with open(sitemap_file, 'w', encoding='utf-8') as f:
                json.dump(sitemap_data, f, ensure_ascii=False, indent=2)
            
            print(f"ğŸ—ºï¸ ì‚¬ì´íŠ¸ë§µ ìƒì„±: {sitemap_file}")
        else:
            print(f"âŒ {character} ìƒì„± ì‹¤íŒ¨")

if __name__ == "__main__":
    main()
